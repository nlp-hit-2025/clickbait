{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:24:21.519949Z",
     "start_time": "2025-05-16T13:23:55.886892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clickbait Detection with Method Attribution - Full Implementation\n",
    "# Configuration\n",
    "# %pip install openai transformers datasets scikit-learn pandas tensorflow dotenv seaborn matplotlib tf-keras ipywidgets requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, multilabel_confusion_matrix\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = requests.session()\n",
    "client.headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"}\n",
    "\n",
    "\n",
    "def dequote(s):\n",
    "    \"\"\"\n",
    "    If a string has single or double quotes around it, remove them.\n",
    "    Make sure the pair of quotes match.\n",
    "    If a matching pair of quotes is not found,\n",
    "    or there are less than 2 characters, return the string unchanged.\n",
    "    \"\"\"\n",
    "    if (len(s) >= 2 and s[0] == s[-1]) and s.startswith((\"'\", '\"')):\n",
    "        return s[1:-1]\n",
    "    return s\n",
    "\n",
    "\n",
    "def openai_request(prompt):\n",
    "    choices = None\n",
    "    while not choices:\n",
    "        response = client.post(url=f'{os.getenv(\"OPENAI_API_URL\")}/chat/completions',\n",
    "                               json=\n",
    "                               {\n",
    "                                   \"model\": os.getenv('OPENAI_API_MODEL'),\n",
    "                                   \"messages\": [{\n",
    "                                       \"role\": \"user\",\n",
    "                                       \"content\": prompt\n",
    "                                   }]\n",
    "                               })\n",
    "        choices = response.json().get('choices', None)\n",
    "        if not choices:\n",
    "            continue\n",
    "\n",
    "    return dequote(choices[0][\"message\"][\"content\"].strip())\n",
    "\n",
    "\n",
    "# 1. Dataset Generation\n",
    "## 1.1 Create clickbait methods catalog\n",
    "METHODS_CATALOG = [\n",
    "    \"Curiosity Gap\", \"Exaggeration\", \"Emotional Triggers\",\n",
    "    \"Sensationalism\", \"Lists/Superlatives\", \"Ambiguous References\",\n",
    "    \"Direct Appeals\", \"Unfinished Narratives\", \"Unexpected Associations\",\n",
    "    \"Provocative Questions\"\n",
    "]\n",
    "if not Path('clickbait_methods.json').exists():\n",
    "    with open('clickbait_methods.json', 'w') as f:\n",
    "        json.dump(METHODS_CATALOG, f)\n",
    "\n",
    "## 1.2 Load real news dataset\n",
    "real_news_df = pd.read_csv('news_data.csv')\n",
    "real_news_df['title'] = real_news_df['title'].apply(lambda cell: cell.encode('ASCII', 'ignore').decode('ASCII'))\n",
    "real_news = list(real_news_df['title'])\n",
    "\n",
    "\n",
    "# 1.3 Modified synthetic data generation with batching\n",
    "def generate_clickbait_batch(batch):\n",
    "    prompt = f\"\"\"\n",
    "    For each headline below, create a clickbait version using ONLY the specified methods.\n",
    "    Do not alter factual content, only style.\n",
    "    Return JSON list without any code blocks or wrappings with items containing:\n",
    "    - \"original\": original headline,\n",
    "    - \"methods_used\": methods applied,\n",
    "    - \"clickbait\": generated text\n",
    "\n",
    "    Headlines with methods: \n",
    "    {json.dumps([{'original': item['original'], 'methods': item['methods']} for item in batch])}\n",
    "    \"\"\"\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < 3:\n",
    "        try:\n",
    "            response = openai_request(prompt)\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            attempts += 1\n",
    "    raise Exception(\"Failed to parse valid JSON after 3 attempts\")\n",
    "\n",
    "\n",
    "# Generate dataset with batching\n",
    "batch_size = 10  # Adjust based on model context window\n",
    "dataset = []\n",
    "\n",
    "if Path('clickbait_dataset.csv').exists():\n",
    "    df = pd.read_csv('clickbait_dataset.csv')\n",
    "else:\n",
    "    for i in tqdm(range(0, len(real_news), batch_size), desc=\"Generating Clickbait\"):\n",
    "        batch = real_news[i:i + batch_size]\n",
    "        batch_data = []\n",
    "\n",
    "        for news in batch:\n",
    "            k = np.random.randint(1, 6)\n",
    "            selected_methods = np.random.choice(METHODS_CATALOG, k, replace=False).tolist()\n",
    "            batch_data.append({\n",
    "                'original': news,\n",
    "                'methods': selected_methods\n",
    "            })\n",
    "\n",
    "        results = generate_clickbait_batch(batch_data)\n",
    "\n",
    "        for res in results:\n",
    "            method_vector = [1 if m in res['methods_used'] else 0 for m in METHODS_CATALOG]\n",
    "            dataset.append({\n",
    "                'source': res['original'],\n",
    "                'clickbait': res['clickbait'],\n",
    "                'methods': method_vector\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_csv('clickbait_dataset.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aviv4\\git\\clickbait\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating Clickbait:   0%|          | 0/870 [00:00<?, ?headline/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa687b30cdb44a75b4a4cf90ad71d9d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 97\u001B[0m\n\u001B[0;32m     95\u001B[0m k \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m6\u001B[39m)\n\u001B[0;32m     96\u001B[0m selected_methods \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(METHODS_CATALOG, k, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 97\u001B[0m clickbait \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_clickbait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnews\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_methods\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m method_vector \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m selected_methods \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m METHODS_CATALOG]\n\u001B[0;32m    100\u001B[0m dataset\u001B[38;5;241m.\u001B[39mappend({\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m'\u001B[39m: news,\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclickbait\u001B[39m\u001B[38;5;124m'\u001B[39m: clickbait,\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmethods\u001B[39m\u001B[38;5;124m'\u001B[39m: method_vector\n\u001B[0;32m    104\u001B[0m })\n",
      "Cell \u001B[1;32mIn[1], line 84\u001B[0m, in \u001B[0;36mgenerate_clickbait\u001B[1;34m(original, methods)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_clickbait\u001B[39m(original, methods):\n\u001B[0;32m     76\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;124m    Create a clickbait version using ONLY these methods:\u001B[39m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(methods)\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;124m    Original: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moriginal\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopenai_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 41\u001B[0m, in \u001B[0;36mopenai_request\u001B[1;34m(prompt)\u001B[0m\n\u001B[0;32m     39\u001B[0m choices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m choices:\n\u001B[1;32m---> 41\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetenv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOPENAI_API_URL\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\n\u001B[0;32m     43\u001B[0m \u001B[43m                           \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m                               \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetenv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOPENAI_API_MODEL\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m                               \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m                                   \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m                                   \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m                               \u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m                           \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     choices \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m choices:\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\requests\\sessions.py:637\u001B[0m, in \u001B[0;36mSession.post\u001B[1;34m(self, url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    626\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    627\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[0;32m    628\u001B[0m \n\u001B[0;32m    629\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 637\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    788\u001B[0m     conn,\n\u001B[0;32m    789\u001B[0m     method,\n\u001B[0;32m    790\u001B[0m     url,\n\u001B[0;32m    791\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    792\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    793\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    794\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    795\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    796\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    797\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    798\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    800\u001B[0m )\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 534\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32m~\\git\\clickbait\\.venv\\lib\\site-packages\\urllib3\\connection.py:516\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    513\u001B[0m _shutdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshutdown\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 516\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    519\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1375\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1374\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1375\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1376\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1377\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. Evaluation Framework\n",
    "## 2.1 Prepare data splits\n",
    "X_detection = df[['source', 'clickbait']].values.flatten()\n",
    "y_detection = [0] * len(df) + [1] * len(df)\n",
    "\n",
    "X_attribution = df['clickbait'].tolist()\n",
    "y_attribution = np.array(df['methods'].tolist())\n",
    "\n",
    "# Train/Test split\n",
    "X_det_train, X_det_test, y_det_train, y_det_test = train_test_split(\n",
    "    X_detection, y_detection, test_size=0.2, random_state=42, stratify=y_detection)\n",
    "\n",
    "X_att_train, X_att_test, y_att_train, y_att_test = train_test_split(\n",
    "    X_attribution, y_attribution, test_size=0.2, random_state=42)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.2 Detection Models\n",
    "## 2.2.1 Logistic Regression Baseline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_det_train_tfidf = tfidf.fit_transform(X_det_train)\n",
    "X_det_test_tfidf = tfidf.transform(X_det_test)\n",
    "\n",
    "# Train\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_det_train_tfidf, y_det_train)\n",
    "\n",
    "# Evaluate\n",
    "lr_preds = lr.predict(X_det_test_tfidf)\n",
    "print(\"Logistic Regression Detection Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_det_test, lr_preds):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_det_test, lr_preds):.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_det_test, lr_preds), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## 2.2.2 BERT Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "\n",
    "# Tokenize\n",
    "X_det_train_bert = tokenizer(X_det_train.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "X_det_test_bert = tokenizer(X_det_test.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Train\n",
    "bert_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "bert_model.fit(X_det_train_bert.data, np.array(y_det_train), epochs=3, batch_size=16)\n",
    "\n",
    "# Evaluate\n",
    "# Predict and process correctly\n",
    "logits = bert_model.predict(X_det_test_bert.data).logits\n",
    "probabilities = tf.sigmoid(logits).numpy().flatten()  # Apply sigmoid\n",
    "bert_preds = (probabilities > 0.5).astype(int)  # Threshold at 0.5\n",
    "print(\"BERT Detection Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_det_test, bert_preds):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_det_test, bert_preds):.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_det_test, bert_preds), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('BERT Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.3 Attribution Models\n",
    "## 2.3.1 Multi-label BERT\n",
    "att_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "att_model = TFBertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(METHODS_CATALOG),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Tokenize\n",
    "X_att_train_tok = att_tokenizer(X_att_train, padding=True, truncation=True, return_tensors='tf')\n",
    "X_att_test_tok = att_tokenizer(X_att_test, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Train\n",
    "att_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "att_model.fit(X_att_train_tok.data, y_att_train, epochs=3, batch_size=16)\n",
    "\n",
    "# Evaluate\n",
    "att_preds = (att_model.predict(X_att_test_tok.data).logits > 0.5).astype(int)\n",
    "print(\"BERT Attribution Results:\")\n",
    "print(f\"Micro F1: {f1_score(y_att_test, att_preds, average='micro'):.2f}\")\n",
    "print(f\"Macro F1: {f1_score(y_att_test, att_preds, average='macro'):.2f}\")\n",
    "\n",
    "# Confusion Matrix (Example for first method)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, method in enumerate(METHODS_CATALOG[:2]):  # Show first 2 methods\n",
    "    cm = multilabel_confusion_matrix(y_att_test, att_preds)[i]\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{method} Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## 2.3.2 Openai_Model Zero-Shot Attribution\n",
    "def openai_model_attribution(text):\n",
    "    prompt = f\"\"\"\n",
    "    Identify which of these methods were used in the headline:\n",
    "    {', '.join(METHODS_CATALOG)}\n",
    "\n",
    "    Headline: {text}\n",
    "    \"\"\"\n",
    "    content = openai_request(prompt)\n",
    "    return [1 if m in content else 0 for m in METHODS_CATALOG]\n",
    "\n",
    "\n",
    "# Create a mapping from clickbait text to its index in X_att_test\n",
    "clickbait_to_index = {clickbait: idx for idx, clickbait in enumerate(X_att_test)}\n",
    "\n",
    "# Get sampled data\n",
    "sample_att = df.loc[df['clickbait'].isin(X_att_test)].sample(10, random_state=42)\n",
    "\n",
    "# Get true labels using clickbait text alignment\n",
    "sample_indices = [clickbait_to_index[cb] for cb in sample_att['clickbait']]\n",
    "y_true = y_att_test[sample_indices]\n",
    "\n",
    "# Generate Openai_Model predictions\n",
    "sample_att['openai_model_methods'] = sample_att['clickbait'].apply(openai_model_attribution)\n",
    "y_openai_model = np.array(sample_att['openai_model_methods'].tolist())\n",
    "\n",
    "# Plot confusion matrices\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, method in enumerate(METHODS_CATALOG[:2]):\n",
    "    cm = confusion_matrix(y_true[:, i], y_openai_model[:, i])\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Openai_Model {method} Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Results Compilation\n",
    "results = {\n",
    "    \"Detection Results\": [\n",
    "        {\n",
    "            \"Model\": \"Logistic Regression\",\n",
    "            \"Accuracy\": accuracy_score(y_det_test, lr_preds),\n",
    "            \"F1\": f1_score(y_det_test, lr_preds)\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"BERT\",\n",
    "            \"Accuracy\": accuracy_score(y_det_test, bert_preds),\n",
    "            \"F1\": f1_score(y_det_test, bert_preds)\n",
    "        }\n",
    "    ],\n",
    "    \"Attribution Results\": [\n",
    "        {\n",
    "            \"Model\": \"Multi-label BERT\",\n",
    "            \"Micro F1\": f1_score(y_att_test, att_preds, average='micro'),\n",
    "            \"Macro F1\": f1_score(y_att_test, att_preds, average='macro')\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pd.DataFrame(results['Detection Results']).to_csv('detection_results.csv')\n",
    "pd.DataFrame(results['Attribution Results']).to_csv('attribution_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNf6NSZnkgSz1EZsRVnxdwU",
   "gpuType": "T4",
   "mount_file_id": "1eA6TTy9bUlB1X9-WVgWYBq6JWG1aGf8u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
